{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e40909",
   "metadata": {},
   "source": [
    "# **Job Placement Predictor**\n",
    "\n",
    "**Submitted by Group 33**  \n",
    "- Ashmit Gupta  \n",
    "- Jolin Lin  \n",
    "- Shikha Rajesh  14573562\n",
    "- Siddhanth Duggal  \n",
    "- Yu Chang 47945050\n",
    "\n",
    "**The University of British Columbia**  \n",
    "**STAT 301**  \n",
    "**Instructor**: Dr. Gabriela Cohen Freue  \n",
    "**Date**: 2025/04/10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cf8bd",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91953b59",
   "metadata": {},
   "source": [
    "In today’s competitive academic environment, securing a placement offer after graduation is a pivotal milestone for students. Institutions often seek ways to improve their placement rates by identifying which factors most strongly influence a student’s likelihood of being placed. This dataset offers a unique opportunity to investigate how well we can build a predictive model that uses students’ activities and scores to accurately forecast their placement status.\n",
    "\n",
    "By focusing on both academic performance and practical experiences, we can explore how these different dimensions of a student’s profile come together to shape placement outcomes. The ultimate goal is to provide actionable insights for educational institutions and students alike, helping them prioritize areas (like upskilling through internships or maintaining strong academic scores) that have the greatest impact on securing a successful placement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70ddca",
   "metadata": {},
   "source": [
    "**Question:** How well can we build a model to accurately predict the placement status of a student based on their relavent activities and scores? \n",
    "\n",
    "... ** TA confirmation: something like this, as we talked with TAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96ba00",
   "metadata": {},
   "source": [
    "# 2. Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0e58b",
   "metadata": {},
   "source": [
    "### a) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e3944",
   "metadata": {},
   "source": [
    "#### Data Description \n",
    "The dataset contains information relating to various factors that affect students' placements. More specifically, it contains information relating to their academic performance (CGPA, aptitude, SSC marks, HSC marks), training (internships, projects, workshops, soft skills), and placement (training, status). We can utilise the above variables to examine which qualities/factors most influence placement decisions. Notably, it has the following features:\n",
    "\n",
    "- Number of variables: 12\n",
    "- Number of observations: 10,000\n",
    "- Variable Information: Included in the following table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a529e22",
   "metadata": {},
   "source": [
    "| Column Name                  | Description                                                                                                                   | Data Type | Variable Type   |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------------|-----------|-----------------|\n",
    "| `StudentID`                 | A unique identifier for each student (1 - 10000).                                                                             | double    | Categorical*    |\n",
    "| `CGPA`                      | Overall cumulative grades achieved by a student (0 - 10 scale).                                                               | double    | Quantitative    |\n",
    "| `Internships`               | Number of internships a student has completed.                                                                                | double    | Quantitative    |\n",
    "| `Projects`                  | Number of projects a student has completed.                                                                                   | double    | Quantitative    |\n",
    "| `Workshops/Certifications` | Number of online workshops/certifications a student has completed to upskill.                                                 | double    | Quantitative    |\n",
    "| `AptitudeTestScore`         | A student's aptitude test score to gauge quantitative and logical thinking (0 - 100).                                         | double    | Quantitative    |\n",
    "| `SoftSkillsRating`          | A student's communication/soft skill rating (1 - 5 scale).                                                                    | double    | Quantitative    |\n",
    "| `ExtracurricularActivities` | Whether a student participates in extracurricular activities (Yes/No).                                                        | character | Categorical     |\n",
    "| `PlacementTraining`         | Whether a student has undergone placement training to ace the placement process (Yes/No).                                     | character | Categorical     |\n",
    "| `SSC_Marks`                 | A student's Senior Secondary Certificate marks (0 - 100).                                                                     | double    | Quantitative    |\n",
    "| `HSC_Marks`                 | A student's Higher Secondary Certificate marks (0 - 100).                                                                     | double    | Quantitative    |\n",
    "| `PlacementStatus`           | Placement outcome (target column with two classes: Placed/Not placed).                                                        | character | Categorical     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ef5dc-9827-4cd5-8dfd-d21ef729cbf5",
   "metadata": {},
   "source": [
    " * Although StudentID is numeric in nature, it is categorical in this context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63db535",
   "metadata": {},
   "source": [
    "#### Data Source and Citation\n",
    "The dataset has been taken from Kaggle (https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data) updated 2 months ago by Kaggle username 'ruchikakumbhar'. It is under the 'CC0: Public Domain' License so the Kaggle user does not endorse this dataset. This also means it is freely available for us to use. The data collection method is not provided in the author's profile nor on the Kaggle dataset webpage, so we would assume it's **observational data**. The citation is as follows:\n",
    "\n",
    "Kumbhar, R. (n.d.). *Placement Prediction Dataset*. Kaggle. Retrieved from [https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data](https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834edbb0",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9914e5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"readr\")\n",
    "# install.packages(\"knitr\") \n",
    "# install.packages(\"dplyr\")\n",
    "# install.packages(\"broom\")\n",
    "# install.packages(\"corrr\")\n",
    "# install.packages(\"car\")\n",
    "# install.packages(\"tidyverse\")\n",
    "# install.packages(\"readr\")\n",
    "# install.packages(\"gridExtra\")\n",
    "# install.packages(\"leaps\")\n",
    "# install.packages(\"corrplot\")\n",
    "# install.packages(\"caret\")\n",
    "\n",
    "#Loading Libs\n",
    "library(readr)\n",
    "library(knitr)\n",
    "library(dplyr)\n",
    "library(broom)\n",
    "library(corrr)\n",
    "library(car)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(gridExtra)\n",
    "library(leaps)\n",
    "library(corrplot)\n",
    "library(RColorBrewer)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(tibble)\n",
    "library(forcats)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02f5e2d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_file_link <- \"https://raw.githubusercontent.com/rainn72/Placement_predictor/refs/heads/main/data/placementdata.csv\"\n",
    "data <- read_csv(data_file_link, show_col_types = FALSE)\n",
    "\n",
    "original_data <- data\n",
    "num_observations <- nrow(data)\n",
    "num_variables <- ncol(data)\n",
    "cat(\"Number of observations:\", num_observations, \"\\n\")\n",
    "cat(\"Number of variables:\", num_variables, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32517b37",
   "metadata": {},
   "source": [
    "#### Initial Data Preprocessing\n",
    "\n",
    "1. we checked if there're duplicated values in the dataset and there are no duplicates that we need to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe759249",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "duplicate_values <- data %>% \n",
    "                    group_by(StudentID) %>% \n",
    "                    summarise(value_count = n()) %>%\n",
    "                    filter(value_count > 1)\n",
    "                    \n",
    "duplicate_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb6749",
   "metadata": {},
   "source": [
    "2. We dropped the variable `StudentID` from out dataset with the following reasons:\n",
    "\n",
    "* **No Predictive Power:** It is simply a unique identifier assigned to each observation (each student). It's not correlated with the student's academic performance. Therefore, it does not help the model distinguish between students who are placed and those who are not.\n",
    "* **Simplicity and Clarity:** Excluding irrelevant variables like IDs keeps our dataset cleaner and our model more interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f8738",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data <- data %>% select(-StudentID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d42b4",
   "metadata": {},
   "source": [
    "3. We changed the name of a covariate because it(\"/\") may raise errors in some following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a0090",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "names(data)[names(data) == \"Workshops/Certifications\"] <- \"Workshops_Certifications\" \n",
    "\n",
    "head(data, 3)\n",
    "\n",
    "unique(data$Workshops_Certifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec317fd9",
   "metadata": {},
   "source": [
    "4. We replaced the levels `NotPlaced` and `Placed` for `PlacementStatus` in the dataset with the numerical values `1` and `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46786b39",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data <- data %>%\n",
    "  mutate(PlacementStatus = if_else(PlacementStatus == \"Placed\", 1, 0))\n",
    "\n",
    "data$PlacementStatus <- factor(data$PlacementStatus,\n",
    "                                 levels = c(\"0\", \"1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b56ef8",
   "metadata": {},
   "source": [
    "5. Convert the Yes/No columns (categorical) to factors and later we will 0-1 encode them for interpretability, and we treat the covariates like `Internships` or `projects` as numeric, which assumes a linear effect between each 'level'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce421c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data$ExtracurricularActivities <- factor(data$ExtracurricularActivities,\n",
    "                                         levels = c(\"No\", \"Yes\"))\n",
    "data$PlacementTraining <- factor(data$PlacementTraining,\n",
    "                                 levels = c(\"No\", \"Yes\"))\n",
    "head(data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4f00d",
   "metadata": {},
   "source": [
    "### b) Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b07277",
   "metadata": {},
   "source": [
    "#### **Data Preprocessing**\n",
    "\n",
    "\n",
    "##### **Check Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c584d88",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colSums(is.na(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f6ac0",
   "metadata": {},
   "source": [
    "Good! The dataset contains no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf58ab0",
   "metadata": {},
   "source": [
    "##### **Check Class Imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c5624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239fed6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns <- c(\"ExtracurricularActivities\", \"PlacementTraining\",\"PlacementStatus\")\n",
    "plots <- list()\n",
    "\n",
    "# Loop over each categorical variable to build a bar plot\n",
    "for (cat_col in categorical_columns) {\n",
    "  p <- ggplot(data = data, aes_string(x = cat_col)) +\n",
    "    geom_bar(fill = \"steelblue\", color = \"black\") +\n",
    "    labs(\n",
    "      title = paste( cat_col),\n",
    "      x = cat_col,\n",
    "      y = \"Count\"\n",
    "    ) +\n",
    "    theme_minimal(base_size = 14) +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 16, face = \"bold\"),\n",
    "      axis.title = element_text(size = 14),\n",
    "      axis.text = element_text(size = 12)\n",
    "    )\n",
    "  plots[[cat_col]] <- p\n",
    "}\n",
    "grid.arrange(grobs = plots, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6fb0b",
   "metadata": {},
   "source": [
    "- There are enough values in both the categorical predictor variables for each of their categories such that there is no reason to merge or drop come categories.\n",
    "- For the response variable (PlacementStatus), there is no class imbalance, so no further tidying is required in this aspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d3aa7",
   "metadata": {},
   "source": [
    "##### **Check Distributional Skewness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03882f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "names(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525023f3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_num <- c(\n",
    "  \"Internships\", \n",
    "  \"Projects\", \n",
    "  \"Workshops_Certifications\",\n",
    "  \"AptitudeTestScore\", \n",
    "  \"SoftSkillsRating\", \n",
    "  \"SSC_Marks\", \n",
    "  \"HSC_Marks\"\n",
    ")\n",
    "\n",
    "plots <- list()\n",
    "\n",
    "for (colname in df_num) {\n",
    "  p <- ggplot(data, aes_string(x = colname)) +\n",
    "    geom_histogram(fill = \"steelblue\", color = \"black\", bins = 15) +  # No extra parentheses here\n",
    "    labs(\n",
    "      title = paste( colname),\n",
    "      x = colname,\n",
    "      y = \"Count\"\n",
    "    ) +\n",
    "    theme_minimal(base_size = 14)\n",
    "  plots[[colname]] <- p\n",
    "}\n",
    "\n",
    "# Arrange all plots in a grid (2 columns, for example)\n",
    "grid.arrange(grobs = plots, ncol = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06490a7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(paste(\"The Number of Students who have Workshop Experience = 3:\", \n",
    "            sum(data$Workshops_Certifications == \"3\")))\n",
    "\n",
    "print(paste(\"The Number of Students who have Workshop Experience = 2:\", \n",
    "            sum(data$Workshops_Certifications == \"2\")))\n",
    "\n",
    "print(paste(\"---------------------------------------------------------------\"))\n",
    "\n",
    "print(paste(\"The Number of Students who have Project number = 1:\", \n",
    "            sum(data$Projects == \"1\")))\n",
    "\n",
    "print(paste(\"The Number of Students who have Project number = 0:\", \n",
    "            sum(data$Projects == \"0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896bba1",
   "metadata": {},
   "source": [
    "**Since there're clearly relative less people with workshop experience = 2, so we will first merge them for now**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cae1e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Pre-process Workshops\n",
    "data <- data %>%\n",
    "  mutate(\n",
    "    Workshops_Certifications = as_factor(Workshops_Certifications),\n",
    "    Workshops_Certifications = fct_collapse(\n",
    "      Workshops_Certifications,\n",
    "      \"2+\" = c(\"2\", \"3\")\n",
    "    )\n",
    "  )\n",
    "#Pre-process Projects\n",
    "data <- data %>%\n",
    "  mutate(\n",
    "    Projects = as_factor(Projects),\n",
    "    Projects = fct_collapse(\n",
    "      Projects,\n",
    "      \"1-\" = c(\"0\", \"1\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "head(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbe993",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "unique(data$Projects)\n",
    "unique(data$Workshops_Certifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41363cdb",
   "metadata": {},
   "source": [
    "By observing the plot above, I would say there is no clearly noticeable heavy skewness for other covariates that may cause problems in the logistic regression model. However, it is evident that, for example, the **AptitudeTestScore** feature has a high frequency of counts at the value of 90.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fb1d8",
   "metadata": {},
   "source": [
    "##### **Two Effective Visualizations**\n",
    "\n",
    "##### **1.Comparison of various scores of students by placement status**\n",
    "- We will create a boxplot of the numerical covariates (CGPA, HSC_Marks, SSC_Marks, AptitudeTestScore, SoftSkillsRating)\n",
    "- This, notably, excludes 3 numerical columns: `Internships`, `Project`s and `Workshops/Certifications`. This is because these columns have only descretised values, which are 0, 1, 2 or 3. Hence, their range, standard deviation and mean would differ a lot from the other numerical variables and thus won't look well on a single plot. Maybe in the future, we could even convert these column into 'factor' type (categorical variables) if it leads to better prediction.\n",
    "- For the visualisation now, we will scale CGPA and SoftSkillsRating to be on the same scale\n",
    "  - We will multiply CGPA by 10 to shift its range from 0-10 to 0-100\n",
    "   - We will multiply SoftSkillsRating by 20 to shift its range 0-5 to 0-100 <br> This is done so a good comparison can be made visually by just looking at the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6a5f1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Main developer: Ashmit Gupta\n",
    "\n",
    "options(repr.plot.width = 11, repr.plot.height = 7)\n",
    "marks_data <- data %>%\n",
    "              mutate(CGPA = CGPA * 10, SoftSkillsRating = SoftSkillsRating * 20) %>% # Scaling CGPA and SoftSkillsRating to be from 1 to 100\n",
    "              pivot_longer(cols = c(CGPA, HSC_Marks, SSC_Marks, AptitudeTestScore, SoftSkillsRating), \n",
    "                           names_to = \"Score_Type\", \n",
    "                           values_to = \"Score\")\n",
    "\n",
    "marks_visualisation <- marks_data %>%\n",
    "                       ggplot(aes(x = Score_Type, y = Score, fill = PlacementStatus)) +\n",
    "                       geom_boxplot() +\n",
    "                       ggtitle(\"Comparison of various scores of students by placement status\") +\n",
    "                       labs(x = \"Score Type\", y = \"Score of the student\") +\n",
    "                       theme(text = element_text(size = 17))\n",
    "                       \n",
    "marks_visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c7af2",
   "metadata": {},
   "source": [
    "This graph is relevant to our research question as it shows the distribution of various possible predictors against the response variable (PlacementStatus). It shows that in general, the students who are placed tend to have a higher median score in the respective academic (or soft skill) category compared to the students who did not get placed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac444cf4",
   "metadata": {},
   "source": [
    "\n",
    "##### **2. Check and Visualize Correlation between Features**\n",
    "\n",
    "To detect whether there's a multicollinearlity issue in the independent variables, we examine it by both the correlation matrix and the variance inflation factor (VIF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0cb6f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "options(repr.plot.width = 15, repr.plot.height = 15)\n",
    "\n",
    "numeric_data <- data %>% select_if(is.numeric)\n",
    "cor_matrix <- cor(numeric_data, use = \"complete.obs\")\n",
    "\n",
    "corrplot(cor_matrix,\n",
    "         method = \"color\",\n",
    "         type = \"upper\",\n",
    "         order = \"hclust\",\n",
    "         tl.col = \"black\",\n",
    "         tl.srt = 45,\n",
    "         col = colorRampPalette(c(\"red\", \"white\", \"blue\"))(200),\n",
    "         title = \"Correlation Matrix\",\n",
    "         mar = c(0,0,1,0),\n",
    "         addCoef.col = \"black\",\n",
    "         number.cex = 0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2805c7",
   "metadata": {},
   "source": [
    "The correlation matrix heatmap indicates all pairs in continuous variables have a positive relationship, moreover, the correlation coefficient between any two pairs are lower than 0.6, suggesting no strong correlation. Therefore, multicollinearlity issue is not concerning at this stage.\n",
    "\n",
    "Next, we will use VIF to detect whether multicollinearlity issue exist among both continuous and categorical independent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f66358",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1) Prepare data for logistic regression\n",
    "\n",
    "vif_data <- data %>%\n",
    "  mutate(ExtracurricularActivities = if_else(ExtracurricularActivities == \"Yes\", 1, 0),\n",
    "         PlacementTraining  = if_else(PlacementTraining  == \"Yes\", 1, 0))\n",
    "\n",
    "# 2) Fit logistic model\n",
    "model_vif <- glm(PlacementStatus ~ ., data = vif_data, family = \"binomial\")\n",
    "\n",
    "# 3) Compute VIF\n",
    "vif_res <- vif(model_vif)\n",
    "\n",
    "vif_res\n",
    "\n",
    "# 4) Extract the scaled GVIF if it's a matrix\n",
    "if (is.matrix(vif_res)) {\n",
    "  scaled_vif <- vif_res[, \"GVIF^(1/(2*Df))\"]\n",
    "  # Preserve the row names as variable names\n",
    "  names(scaled_vif) <- rownames(vif_res)\n",
    "} else {\n",
    "  # If vif_res is already a named vector (no factors), just use it\n",
    "  scaled_vif <- vif_res\n",
    "}\n",
    "\n",
    "# 5) Make a barplot with one bar per predictor\n",
    "barplot(\n",
    "  scaled_vif,\n",
    "  main      = \"VIF (Scaled) for Each Predictor\",\n",
    "  names.arg = names(scaled_vif),\n",
    "  las       = 2,                         \n",
    "  cex.names = 0.8,                      \n",
    "  col       = \"steelblue\",\n",
    "  ylim      = c(0, max(scaled_vif) + 0.5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a254e1",
   "metadata": {},
   "source": [
    "The VIF value for each variable are all just slightly higher than 1, suggesting a low correlation between predictor variables based on the rules of thumb of VIF (GVIF ~= 1 indicating little to no multicollinearity). \n",
    "\n",
    "This is a more formal way to check and visualize the result concluded by correlation matrix, Generalized VIF suggests multicollinearlity issue is not concerning at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99012f3a",
   "metadata": {},
   "source": [
    "### **c) Methods: Plan**\n",
    "\n",
    "#### **Method Used and Justifications**\n",
    "For this prediction assignment, we propose using **Logistic Regression** to model and analyze the relationship between students' various measurements and their placement status.\n",
    "\n",
    "#### Why is this method appropriate?\n",
    "**Logistic Regression** is well-suited for binary classification problems because it models  the log-odds of the outcome as a linear function of explanatory variables. This allows us to quantify the **strength of association** between each explanatory variables and the likelihood of being placed for a job.\n",
    "\n",
    "Also, it is easy to implement and interpret. The coefficients provide direct insight into how each covariate affects the log-odds of being placed or not, and p-values and confidence intervals (CIs) for the model coefficients are straightforward to generate. This is particularly valuable when I need to explain the model's decisions to non-technical stakeholders.\n",
    "\n",
    "##### Which assumptions are required to apply the method selected?\n",
    "* **Independence of Observations**: Each observation should be independent of the others.\n",
    "* **Binary Response**: The response variable is binary.\n",
    "* **Sample Size**: The sample size is large enough (which is satisfied in our case).\n",
    "* **Linearity**: There should be a linear relationship between the independent variables (explanatory) and the log odds of the dependent variable (response).\n",
    "* **Multicollinearity**: After data cleaning, there should be little or no multicollinearity among the independent variables.\n",
    "\n",
    "##### Potential Limitations or Weaknesses of the Method Selected\n",
    "* **Model Simplicity**: While logistic regression is straightforward, it may not capture complex non-linear relationships or interactions among variables as effectively as more advanced methods. Although it offers great interpretability, it might not provide the highest predictive accuracy compared to more complex models.\n",
    "* **Outliers and Class Imbalance**: Logistic Regression is sensitive to outliers in the covariate space, which can affect the estimated coefficients and potentially skew the model's performance. Additionally, imbalanced classes may affect model performance if not addressed with appropriate techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b2611",
   "metadata": {},
   "source": [
    "#### **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183bc1a",
   "metadata": {},
   "source": [
    "For predictive modeling best practices, we will split the data and do cross-validation to avoid overfitting and to better estimate out-of-sample performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001bcfa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Split data into train & test sets\n",
    "set.seed(123)  # for reproducibility\n",
    "train_index <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))\n",
    "train_data  <- data[train_index, ]\n",
    "test_data   <- data[-train_index, ]\n",
    "\n",
    "head(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba715af",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2) Define a trainControl() object for k-fold CV\n",
    "train_control <- trainControl(\n",
    "  method = \"cv\",         # k-fold CV\n",
    "  number = 10,           # for 10-fold\n",
    "  savePredictions = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22bbe4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#3) Fit a model and do feature selection \n",
    "model_cv <- train(\n",
    "  PlacementStatus ~ .,  \n",
    "  data       = train_data,\n",
    "  method     = \"glmStepAIC\",  # stepwise logistic\n",
    "  family     = binomial,\n",
    "  trControl  = train_control\n",
    ")\n",
    "#model_cv\n",
    "summary(model_cv$finalModel)\n",
    "\n",
    "finalmodel1 <- model_cv$finalModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05babcfc",
   "metadata": {},
   "source": [
    "**How the test data created and used :**\n",
    "\n",
    "* We manually split the train and test data. Then we performed a 10-fold-cros-validation on the training data only, within each fold, we run a stepwise logistic regression to choose covariates (based on AIC). After that, aggregating performance across the 10 folds to decide the best final overall model.\n",
    "* Note that we kept the test data locked and it wasn't used in fitting or selecting the model, only for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1470cd",
   "metadata": {},
   "source": [
    "**A brief Interpretation of the results:**\n",
    "\n",
    "Note that in the summary output of the logistic regression model, the covariate **Internships** was not selected (dropped) by StepAIC, indicating that it may have little predictive effect on the response variable.\n",
    "\n",
    "\n",
    "maybe adding things here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d611995",
   "metadata": {},
   "source": [
    "**Performing a careful model assessment and showing visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d77464",
   "metadata": {},
   "source": [
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d770b0d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction and Reporting \n",
    "\n",
    "test_probs  <- predict(model_cv, newdata = test_data, type = \"prob\")[, \"1\"]\n",
    "test_class   <- ifelse(test_probs > 0.5, \"Placed\", \"NotPlaced\")\n",
    "\n",
    "# Convert predictions and test outcomes to factors (0/1) for confusionMatrix\n",
    "test_pred_factor <- factor(test_pred, levels = c(0,1))\n",
    "test_out_factor  <- factor(test_data$PlacementStatus, levels = c(0,1))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Evaluate performance\n",
    "# -----------------------------------------------------\n",
    "conf_mat <- confusionMatrix(test_pred_factor, test_out_factor)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f876fe",
   "metadata": {},
   "source": [
    "Our logistic regression model achieves about 79.83% accuracy, indicating that it generally distinguishes “Placed” vs. “Not Placed” students well. A Sensitivity of around 83% and a Specificity of about 0.783 all suggest a balanced performance between identifying truly placed students and minimizing false alarms. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a98a4",
   "metadata": {},
   "source": [
    "2. Check ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eacb2f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "roc_obj <- roc(response = test_data$PlacementStatus,\n",
    "               predictor = test_probs,\n",
    "               levels = c(\"0\",\"1\"))\n",
    "auc_val <- auc(roc_obj)\n",
    "plot(roc_obj)\n",
    "\n",
    "\n",
    "auc_val #area under the ROC Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f703f7-d4b7-49e8-b99e-42af39558520",
   "metadata": {},
   "source": [
    "This ROC curve shows how well our model can tell the difference between placed and not placed students. With an AUC (Area Under the Curve) of 0.877, the curve hugs the top-left corner, meaning the model performs very well across different threshold values. In simple terms, it’s good at ranking students by their likelihood of getting placed—even beyond just a 0.5 cut-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a60d2",
   "metadata": {},
   "source": [
    "3. Overfitting/Underfitting Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22590dcd-c292-44ee-8bac-b6f839f76c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results <- model_cv$resample\n",
    "mean_cv_accuracy <- mean(cv_results$Accuracy)\n",
    "\n",
    "test_probs <- predict(model_cv, newdata = test_data, type = \"prob\")[, \"1\"]\n",
    "test_pred <- ifelse(test_probs > 0.5, 1, 0)\n",
    "test_pred_factor <- factor(test_pred, levels = c(0, 1))\n",
    "test_out_factor <- factor(test_data$PlacementStatus, levels = c(0, 1))\n",
    "\n",
    "conf_mat <- confusionMatrix(test_pred_factor, test_out_factor)\n",
    "test_accuracy <- conf_mat$overall[\"Accuracy\"]\n",
    "\n",
    "cat(\"Mean CV Accuracy (Train Set):\", round(mean_cv_accuracy, 4), \"\\n\")\n",
    "cat(\"Test Set Accuracy:\", round(test_accuracy, 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acc56c-20a7-470d-9b49-003437154d8e",
   "metadata": {},
   "source": [
    "The test set accuracy of 79.83% aligns closely with the cross-validated training accuracy of 79.94%, as shown. The near-identical values is a great sign, it means the model is consistent and not just memorizing the training data. It performs similarly on data it hasn’t seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1eb13-c555-4bac-bf6a-1533de30ae3c",
   "metadata": {},
   "source": [
    "- Plot to visualize Performance Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdeed8-64a4-4641-99e4-e9a61d154944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot comparing train (CV) vs. test accuracy\n",
    "accuracy_df <- data.frame(\n",
    "  Dataset = c(\"Train (CV)\", \"Test\"),\n",
    "  Accuracy = c(mean_cv_accuracy, test_accuracy)\n",
    ")\n",
    "\n",
    "ggplot(accuracy_df, aes(x = Dataset, y = Accuracy, fill = Dataset)) +\n",
    "  geom_col(width = 0.5) +\n",
    "  ylim(0, 1) +\n",
    "  geom_text(aes(label = round(Accuracy, 3)), vjust = -0.5, size = 5) +\n",
    "  labs(title = \"Model Accuracy: Train (CV) vs. Test\",\n",
    "       y = \"Accuracy\") +\n",
    "  theme_minimal(base_size = 14) +\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78b000-88a9-470c-8f61-41dc98d0cb19",
   "metadata": {},
   "source": [
    "This bar chart visually compares accuracy on the training data (via cross-validation) and the test data. The bars are nearly the same height (both around 79.8%), confirming that the model generalizes well. There’s no sign of overfitting (doing well on training but badly on test), and no underfitting either (doing badly on both). This adds confidence that the model is reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b6ae01",
   "metadata": {},
   "source": [
    "# 3. Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d8d90-687b-489e-92be-e511979b31e5",
   "metadata": {},
   "source": [
    "Our primary goal was to evaluate how well a logistic regression model can predict student placement status using academic scores, co-curricular activities, and training indicators. The final model achieved a test set accuracy of 79.83% and a nearly identical cross-validated (CV) training accuracy of 79.94%, suggesting excellent generalization performance with no evidence of overfitting or underfitting. This is further supported by the ROC AUC of 0.877, indicating strong discriminative power.\n",
    "\n",
    "**Key Findings & Implications**\n",
    "The most impactful predictors based on model coefficients include:\n",
    "\n",
    "- PlacementTrainingYes (β = 0.96) and ExtracurricularActivitiesYes (β = 0.79), highlighting the real-world value of training and non-academic development.\n",
    "\n",
    "- AptitudeTestScore (β = 0.07), SoftSkillsRating (β = 0.62), and CGPA (β = 0.35) are all statistically significant (p < 0.001), aligning with expectations that stronger academic and aptitude performance increases placement likelihood.\n",
    "\n",
    "- Participation in Projects (especially Projects3, β = 0.55) and Workshops_Certifications also show meaningful positive associations.\n",
    "\n",
    "These findings imply that holistic student development, not just academic achievement, plays a major role in employability. Institutions may leverage this insight to encourage project-based learning and soft skill training.\n",
    "However, while the model predicts well, it is essential to recognize that these relationships are associational, not causal. For instance, students who undergo placement training may already be more motivated or better prepared. Thus, we cannot conclude that training *causes* placement success.\n",
    "\n",
    "**Expectations vs. Results**\n",
    "The results closely align with expectations: academic performance (CGPA), aptitude (AptitudeTestScore), and interpersonal ability (SoftSkillsRating) were anticipated to be strong predictors. Notably, PlacementTraining emerged as the most influential categorical variable, reinforcing the importance of structured preparation programs.\n",
    "\n",
    "Interestingly, Internships was dropped during stepwise feature selection due to a lack of statistical contribution (∆AIC ≈ -25). This may reflect low variability or limited effect in this dataset.\n",
    "\n",
    "**Model Improvement Opportunities**\n",
    "While performance metrics are strong, the model could be refined in the following ways:\n",
    "\n",
    "- The right-skewed AptitudeTestScore, especially a peak at 90, suggests potential bias. Binning or transforming this variable may improve fit and meet linearity assumptions.\n",
    "\n",
    "- Testing non-linear models could help capture interactions and non-additive effects that logistic regression may miss.\n",
    "\n",
    "- The current probability threshold (0.5) could be adjusted to better balance sensitivity (83%) and specificity (75%), depending on whether minimizing false positives or false negatives is more important to the people interested.\n",
    "\n",
    "**Future Research Directions**\n",
    "- Use causal inference techniques to better understand the true effect of factors like PlacementTraining.\n",
    "\n",
    "- Include institution-level data (e.g., college rank, company connections) to expand the model’s generalizability.\n",
    "\n",
    "- Investigate interaction effects, such as whether the benefit of soft skills or certifications is amplified when paired with training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30911",
   "metadata": {},
   "source": [
    "# 4. References\n",
    "- Dataset has downloaded from Kaggle (https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data)\n",
    "- All the information (like data description, number of variables, number of observations, variable name, variable type and variable description) in the main 'Data Description' section has been adapted from https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
